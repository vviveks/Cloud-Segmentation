{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-23T19:19:22.459008Z","iopub.execute_input":"2021-05-23T19:19:22.459352Z","iopub.status.idle":"2021-05-23T19:19:36.684967Z","shell.execute_reply.started":"2021-05-23T19:19:22.45928Z","shell.execute_reply":"2021-05-23T19:19:36.679897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Neccesary Imports\nimport os\nimport cv2\nimport wandb\nimport time\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport torchvision\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport albumentations as A\nimport torch.optim as optim\nfrom PIL import Image\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom pathlib import Path\nimport torch.nn.functional as F\nfrom tqdm.auto import tqdm","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.685903Z","iopub.status.idle":"2021-05-23T19:19:36.686272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.manual_seed(42)\n#42? You know why ","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.687294Z","iopub.status.idle":"2021-05-23T19:19:36.687826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original_height=384\noriginal_width =384\n\n#Albumentations Transformations\ntransformations = A.Compose([\n    A.VerticalFlip(p=0.5),              \n    A.RandomRotate90(p=0.5),\n    A.RandomGamma(p=0.8),\n    ])\n#Highly Inspired from the Original shared notebook : 38-Cloud-Data preparation by cordmau\nclass Clouds(Dataset):\n    def __init__(self, r_dir, g_dir, b_dir, nir_dir, gt_dir,transform=False):\n        super().__init__()\n        \n        # Looping through the files in red folder and combine, into a dictionary, the other bands\n        self.files = [self.combine_files(f, g_dir, b_dir, nir_dir, gt_dir) for f in r_dir.iterdir() if not f.is_dir()]\n        self.transform = transform\n        \n    def combine_files(self, r_file: Path, g_dir, b_dir,nir_dir, gt_dir):\n        \n        files = {'red': r_file, \n                 'green':g_dir/r_file.name.replace('red', 'green'),\n                 'blue': b_dir/r_file.name.replace('red', 'blue'), \n                 'nir': nir_dir/r_file.name.replace('red', 'nir'),\n                 'gt': gt_dir/r_file.name.replace('red', 'gt')}\n\n        return files\n                                       \n    def __len__(self):\n        \n        return len(self.files)\n     \n    def get_image(self, idx):\n\n        image = np.stack([np.array(Image.open(self.files[idx]['red'])),\n                            np.array(Image.open(self.files[idx]['green'])),\n                            np.array(Image.open(self.files[idx]['blue'])),\n                           ], axis=2)\n        \n        nir = np.expand_dims(np.array(Image.open(self.files[idx]['nir'])), 2)\n        image = np.concatenate([nir,image], axis=2)\n            \n        # normalizing according to the paper\n        return (image / np.iinfo(image.dtype).max)\n    \n\n    def get_mask(self, idx):\n        \n        mask = np.array(Image.open(self.files[idx]['gt']))\n        mask = np.where(mask==255, 1, 0)#Semantic Segmentaion, so 1- Clouds, 0-Background.\n        return mask\n    \n    def __getitem__(self, idx):\n                    \n        x = self.get_image(idx)\n        \n        y = self.get_mask(idx)\n       \n        if self.transform is not None:\n            augmented = self.transform(image=x,mask=y)\n            x=augmented['image']\n            y=augmented['mask']\n            \n        x=torch.from_numpy(x)\n        y=torch.tensor(y,dtype=torch.float32) \n        x = x.permute(2,0,1)#Numpy -> PyTorch\n        \n        return x.double(), y.unsqueeze(0)#Need the mask to be of [1,H,W] beacuse of output of the network is of similar dimensions\n    \n    def open_as_pil(self, idx):\n        \n        arr = 256*self.open_as_array(idx)\n        \n        return Image.fromarray(arr.astype(np.uint8), 'RGB')\n    \n    def __repr__(self):\n        s = 'Dataset class with {} files'.format(self.__len__())\n\n        return s\n#MY OWN VERSION BUT IT IS TO A BIT SLOW\noriginal_height=384\noriginal_width =384\noriginal_height=256\noriginal_width =256\n\ntransformed = A.Compose([\n    A.Resize(256,256),\n    A.OneOf([\n        A.RandomSizedCrop(min_max_height=(50, 101), height=original_height, width=original_width, p=0.5),\n        A.PadIfNeeded(min_height=original_height, min_width=original_width, p=0.5)\n    ], p=1),    \n    A.VerticalFlip(p=0.5),              \n    A.RandomRotate90(p=0.5),\n    A.OneOf([\n        A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03, p=0.5),\n        A.GridDistortion(p=0.5),\n        A.OpticalDistortion(distort_limit=2, shift_limit=0.5, p=1)                  \n        ], p=0.8),\n    #A.CLAHE(p=0.8),\n    #A.RandomBrightnessContrast(p=0.8),    \n    A.RandomGamma(p=0.8),\n    ])\n\ndef get_channels(path):\n    red_ch=os.listdir(path+'train_red')\n    blue_ch=os.listdir(path+'train_blue')\n    green_ch=os.listdir(path+'train_green')\n    nir_ch=os.listdir(path+'train_nir')\n    masks=os.listdir(path+'train_gt')\n    return red_ch,blue_ch,green_ch,nir_ch,masks\n\n#f=transforms.ToTensor()\ndef f(image):\n    return np.array(image)\n\ndef get_image(path,r,b,g,n,m):\n    red=f(Image.open(path+'train_red/'+r))\n    blue=f(Image.open(path+'train_blue/'+b))\n    green=f(Image.open(path+'train_green/'+g))\n    nir=f(Image.open(path+'train_nir/'+n))\n    mask=f(Image.open(path+'train_gt/'+m))\n    return red,blue,green,nir,mask\n\npath='../input/38cloud-cloud-segmentation-in-satellite-images/38-Cloud_training/'\n\nclass Clouds(Dataset):\n    \n    def __init__(self,path,transform=None,num_channels=4):\n        \n        self.path=path\n        self.transform=transform\n        self.channels=get_channels(path)\n        self.num_channels=num_channels\n       \n    def process(self,r,g,b,n,m):\n        r,g,b,n,m=get_image(path,r,g,b,n,m)\n        image = np.stack([n,r,g],axis=2)\n        mask=m\n        return image,mask\n        \n    def __getitem__(self,idx):\n        \n        r=self.channels[0][idx]\n        g=self.channels[1][idx]\n        b=self.channels[2][idx]\n        n=self.channels[3][idx]\n        m=self.channels[4][idx]\n        \n        image,mask=self.process(r,g,b,n,m)\n        image = image.astype('uint16')\n        image = image / np.iinfo(image.dtype).max\n        mask  = mask/255.0\n       \n        if self.transform is not None:\n      \n            augmented = self.transform(image=image,mask=mask)\n            image=torch.from_numpy(augmented['image']).permute(2,0,1)\n            mask=torch.from_numpy(augmented['mask']) \n            \n        image=image.double()\n        mask=mask.unsqueeze(0)\n        mask = mask.type(torch.float32)\n        return image,mask\n    \n    def __len__(self):\n        return len(self.channels[0])\n       \n\n#dataset=Clouds(path,transform=transformed)\n#image,mask=dataset[2]\n#plt.imshow(image.permute(1,2,0))","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.690708Z","iopub.status.idle":"2021-05-23T19:19:36.691272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image,label=dataset[2]\nplt.imshow(image.permute(1,2,0))","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.692325Z","iopub.status.idle":"2021-05-23T19:19:36.692895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_path = Path('../input/38cloud-cloud-segmentation-in-satellite-images/38-Cloud_training')\ndataset = CloudDataset(base_path/'train_red', \n                    base_path/'train_green', \n                    base_path/'train_blue', \n                    base_path/'train_nir',\n                    base_path/'train_gt',transform=transformations)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.694151Z","iopub.status.idle":"2021-05-23T19:19:36.694728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_length=int(0.712* len(dataset))\n\ntest_length=len(dataset)-train_length\n\n\ntrain_dataset,test_dataset=torch.utils.data.random_split(dataset,(train_length,test_lengt))\nbatch_size= 12 \n\ntrainloader = DataLoader(train_dataset,\n        batch_size=batch_size, shuffle=True,num_workers= 2)\ntestloader = DataLoader(test_dataset,\n        batch_size=batch_size, shuffle=False,num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.69593Z","iopub.status.idle":"2021-05-23T19:19:36.696481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Metrics(inputs, targets):\n    \n    inputs = torch.sigmoid(inputs)\n    inputs=inputs.round().int()\n    targets=targets.int()\n    smooth = 1.0\n    inputs = inputs.view(-1)\n    targets = targets.view(-1)\n    intersection = (inputs & targets).float().sum()\n    TP=intersection\n    FP = ((1-targets) & inputs).float().sum()\n    FN = (targets & (1-inputs)).float().sum()\n    TN = ((1-targets) & (1-inputs)).float().sum()\n    total = (inputs + targets).float().sum()\n    union = total - intersection \n    IoU = ((intersection + smooth)/(union + smooth))\n    # 'Dice':dice, 'Pixel_Acc': acc, 'Precision': precision,'Recall': recall, 'Specificity':specificity}\n    #return metrics\n    \n    dice = (2.0 * intersection + smooth) / (total + smooth)\n    IoU = ((intersection + smooth)/(union + smooth))\n    valid = (targets >= 0)\n    acc_sum = (valid * (inputs == targets)).sum()\n    valid_sum = valid.sum()\n    #acc2=(inputs.argmax(dim=1) == targets.float().mean()\n    acc = (float(acc_sum) / (valid_sum + 1e-10))\n    precision = (intersection/(FP+intersection+1e-5))\n    recall = (intersection/(FN+intersection+1e-5))\n    specificity = (TN/(TN+FP+1e-5))\n    metrics={'IoU':IoU,'Dice':dice, 'Pixel_Acc': acc, 'Precision': precision,'Recall': recall, 'Specificity':specificity}\n    return metrics\n","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.697606Z","iopub.status.idle":"2021-05-23T19:19:36.698197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Sorry for this, I have attached the scratch implementations which failed in the bottom.\n!pip install segmentation_models_pytorch \nimport segmentation_models_pytorch as smp\n\nmodel = smp.Unet(\n    encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7,     # use `imagenet` pre-trained weights for encoder initialization\n    in_channels=4,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n    classes=1,                      # model output channels (number of classes in your dataset)\n)\n\n#mask=torch.randn(4,1,384,384)\n#target=torch.randn(4,1,384,384)\n\n\n#z=m(target,mask)\ndevice = \"cpu\"\n\nif torch.cuda.is_available():\n    device = \"cuda\"\n\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.699272Z","iopub.status.idle":"2021-05-23T19:19:36.699811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Metrics(inputs, targets):\n    inputs = torch.sigmoid(inputs)\n    inputs=inputs.round().int()\n    targets=targets.round().int()\n    smooth = 1.0\n    inputs = inputs.view(-1)\n    targets = targets.view(-1)\n    intersection = (inputs & targets).float().sum()\n    TP=intersection\n    FP = ((1-targets) & inputs).float().sum()\n    FN = (targets & (1-inputs)).float().sum()\n    TN = ((1-targets) & (1-inputs)).float().sum()\n    total = (inputs + targets).float().sum()\n    union = total - intersection \n    dice = (2.0 * intersection + smooth) / (total + smooth)\n    IoU = ((intersection + smooth)/(union + smooth))\n    valid = (targets >= 0)\n    acc_sum = (valid * (inputs == targets)).sum()\n    valid_sum = valid.sum()\n    acc = (float(acc_sum) / (valid_sum + 1e-10))\n    precision = (intersection/(FP+intersection+1e-5))\n    recall = (intersection/(FN+intersection+1e-5))\n    specificity = (TN/(TN+FP+1e-5))\n    metrics={'IoU':IoU, 'Dice':dice, 'Pixel_Acc': acc, 'Precision': precision,'Recall': recall, 'Specificity':specificity}\n    return metrics\n","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.701013Z","iopub.status.idle":"2021-05-23T19:19:36.70154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef train(network,criterion, optimizer, trainloader):\n    loss_train = 0\n    acc_train = 0\n    network.train()\n    \n    for step in tqdm(range(len(trainloader))):\n\n        images , masks = next(iter(trainloader))\n        \n        # move the images and labels to GPU\n        images = images.to(device)\n        masks = masks.to(device)\n      \n\n        pred = network(images)\n        #pred=torch.sigmoid(pred)\n      \n        # clear all the gradients before calculating them\n        optimizer.zero_grad()\n        #print(masks.shape,images.shape)\n        # find the loss for the current step\n        loss_train_step= criterion(pred , masks)\n        \n        # find accuracy\n        acc_train_ = Metrics(pred,masks)\n        acc_train_step=acc_train_['IoU']\n        # calculate the gradients\n        loss_train_step.backward()\n        #print(loss_train_step,masks.shape)\n        #print(acc_train_)\n        # update the parameters\n        optimizer.step()\n        \n        loss_train += loss_train_step.item()\n        acc_train += acc_train_step  \n            \n    loss_train /= len(trainloader)\n    acc_train /= len(trainloader)\n\n    return loss_train, acc_train,acc_train_  \n        \ndef validate(network,criterion, testloader): \n    loss_valid = 0\n    acc_valid = 0       \n    network.eval()  \n\n    for step in tqdm(range(len(testloader))):\n\n        images , masks = next(iter(testloader))\n        \n        # move the images and labels to GPU\n        images = images.to(device)\n        masks = masks.to(device)\n        \n        \n        pred = network(images)\n        #pred=torch.sigmoid(pred)\n        \n      \n        # clear all the gradients before calculating them\n        optimizer.zero_grad()\n        \n        # find the loss and acc for the current step\n        \n        loss_valid_step = criterion(pred , masks)\n        \n        # find accuracy\n        val_metrics=Metrics(pred,masks)\n        acc_valid_step=val_metrics['IoU']\n        acc_val = val_metrics\n        loss_valid += loss_valid_step.item()\n        acc_valid += acc_valid_step\n        #print(loss_tvalid_step,masks.shape)\n        #print(acc_val)\n\n    loss_valid /= len(testloader)\n    acc_valid /= len(testloader)\n\n    return loss_valid, acc_valid,acc_val","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.702684Z","iopub.status.idle":"2021-05-23T19:19:36.703265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\nwandb.login()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nwandb.init(name='Clouds', \n           project='UnNet+WeightedBCE',\n           notes='RGBNIR', \n           #tags=['Replay-Attack','Cyclic_LR'],\n           entity='creganstark')\n\n# WandB Configurations (optional)        \nwandb.config.lr = 5e-3 \n#model=UNet()\nmodel=model.double()\nmodel = model.to(device)\n\n#criterion = FocalTverskyLoss()\ncriterion=nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.3053))\noptimizer = optim.Adam(model.parameters(),lr  =  wandb.config.lr)# ,\n                      #momentum     = 0.9,\n                      #nesterov     = True,\n                      #weight_decay = 5e-4)\n\n#scheduler = optim.lr_scheduler.CyclicLR(optimizer,base_lr=wandb.config.lr,max_lr=1e-3 ,step_size_up=2000)\n\n\n# Log the network weight histograms \nwandb.watch(model)\n\nnum_epochs = 20\nstart_time = time.time()\nprev_acc=0\nfor epoch in range(1, num_epochs+1):\n    \n    loss_train, acc_train,metric_train = train(model, criterion, optimizer, trainloader)\n    loss_valid, acc_valid,metric_val = validate(model, criterion, testloader)\n    \n    print('Epoch: {}  Train Loss: {:.4f}  Train IoU: {:.4f}  Valid Loss: {:.4f}  Valid IoU: {:.4f}'.\n          format(epoch, loss_train, acc_train, loss_valid, acc_valid))\n\n    # Log the loss and accuracy values at the end of each epoch\n    wandb.log({\n        \"Epoch\": epoch,\n        \"Train IoU\": metric_train['IoU'],\n        \"Train Dice\": metric_train['Dice'],\n        \"Train Pixel Acc\": metric_train['Pixel_Acc'],\n        \"Train Precision\":metric_train[\"Precision\"],\n        \"Train Recall\": metric_train['Recall'],\n        \"Train Specificity\":metric_train['Specificity'],\n        \"Train Loss\": loss_train,\n        \"Val IoU\": metric_val['IoU'],\n        \"Val Dice \": metric_val['Dice'],\n        \"Val Pixel Acc\": metric_val['Pixel_Acc'],\n        \"Val Precision\":metric_val[\"Precision\"],\n        \"Val Recall\": metric_val['Recall'],\n        \"Val Specificity\":metric_val['Specificity'],\n        \"Val Loss\" : loss_valid\n       })\n    if acc_valid>prev_acc:\n      prev_acc=acc_valid\n      paths = \"model\"+str(acc_valid)+\".pt\"\n      print('Saving Model')\n      torch.save({\n          'epoch': epoch,\n          'model_state_dict': model.state_dict(),\n          'optimizer_state_dict': optimizer.state_dict(),\n          'val_loss': loss_valid,\n          'val_acc':acc_valid,\n          'train_acc':acc_train,\n          'loss_acc':loss_train,\n          }, str(paths))\n\nprint(\"Time Elapsed : {:.4f}s\".format(time.time() - start_time))","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.706133Z","iopub.status.idle":"2021-05-23T19:19:36.706655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Inference","metadata":{}},{"cell_type":"code","source":"#For Loading from last checkpoint\nfilename='../input/finalbce50/finalbce50.pt'\n\ndef load_checkpoint(model,filepath):\n    checkpoint = torch.load(filepath)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    #for parameter in model.parameters():\n        #parameter.requires_grad = True\n    return model\n#model=load_checkpoint(model,filename)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.707717Z","iopub.status.idle":"2021-05-23T19:19:36.708267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.3053))\nmodel=model.double()\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.709445Z","iopub.status.idle":"2021-05-23T19:19:36.710025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Metrics(inputs, targets):\n    \n    inputs = torch.sigmoid(inputs)\n    inputs=inputs.round().int()\n    targets=targets.int()\n    smooth = 1.0\n    inputs = inputs.view(-1)\n    targets = targets.view(-1)\n    intersection = (inputs & targets).float().sum()\n    TP=intersection\n    FP = ((1-targets) & inputs).float().sum()\n    FN = (targets & (1-inputs)).float().sum()\n    TN = ((1-targets) & (1-inputs)).float().sum()\n    total = (inputs + targets).float().sum()\n    union = total - intersection \n    IoU = ((intersection + smooth)/(union + smooth))\n    # 'Dice':dice, 'Pixel_Acc': acc, 'Precision': precision,'Recall': recall, 'Specificity':specificity}\n    #return metrics\n    \n    dice = (2.0 * intersection + smooth) / (total + smooth)\n    IoU = ((intersection + smooth)/(union + smooth))\n    valid = (targets >= 0)\n    acc_sum = (valid * (inputs == targets)).sum()\n    valid_sum = valid.sum()\n    #acc2=(inputs.argmax(dim=1) == targets.float().mean()\n    acc = (float(acc_sum) / (valid_sum + 1e-10))\n    precision = (intersection/(FP+intersection+1e-5))\n    recall = (intersection/(FN+intersection+1e-5))\n    specificity = (TN/(TN+FP+1e-5))\n    metrics={'IoU':IoU,'Dice':dice, 'Pixel_Acc': acc, 'Precision': precision,'Recall': recall, 'Specificity':specificity}\n    return metrics\ndef validate2(network,criterion, testloader): \n    \n    #train_dataset,test_dataset=torch.utils.data.random_split(dataset,(6000,2400))\n    \n\n    #batch_size= 12\n\n    \n   # testloader = DataLoader(test_dataset,\n        #batch_size=batch_size, shuffle=False,num_workers=2)\n    \n    \n    loss_valid = 0\n    acc_valid = 0    \n    acc_pix = 0\n    acc_dice=0\n    precision=0\n    recall=0\n    specificity=0\n    network.eval()  \n\n    for step in tqdm(range(len(testloader))):\n\n        images , masks = next(iter(testloader))\n        \n        # move the images and labels to GPU\n        images = images.to(device)\n        masks = masks.to(device)\n        \n        \n        pred = network(images)\n        \n        \n        loss_valid_step = criterion(pred , masks)\n       \n        val_metrics=Metrics(pred,masks)\n        \n        #acc_val = val_metrics\n        acc_valid_step=val_metrics['IoU']\n        acc_valid_dice=val_metrics['Dice']\n        acc_valid_pixel=val_metrics['Pixel_Acc']\n        acc_precision=val_metrics['Precision']\n        acc_recall = val_metrics['Recall']\n        acc_speicificity = val_metrics['Specificity']\n        precision+=acc_precision\n        recall+=acc_recall\n        specificity+=acc_speicificity\n        loss_valid += loss_valid_step.item()\n        acc_valid += acc_valid_step\n        acc_pix+=acc_valid_pixel\n        acc_dice+=acc_valid_dice\n        \n        \n        #print(loss_tvalid_step,masks.shape)\n        #print(acc_val)\n\n    loss_valid /= len(testloader)\n    acc_valid /= len(testloader)\n    acc_pix/= len(testloader)\n    acc_dice/= len(testloader) \n    precision/=len(testloader) \n    recall/=len(testloader) \n    specificity/=len(testloader) \n    \n\n    return loss_valid,acc_valid,acc_pix,acc_dice,precision,recall,specificity","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.711262Z","iopub.status.idle":"2021-05-23T19:19:36.711803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_valid,acc_valid,acc_pix,acc_dice,precision,recall,specificity=validate2(model,criterion, testloader)\nloss_valid,acc_valid,acc_pix,acc_dice,precision,recall,specificity","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.712839Z","iopub.status.idle":"2021-05-23T19:19:36.713402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clutter from all the runs\nNotebook ends here","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_valid,acc_valid,acc_pix,acc_dice,precision,recall,specificity","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.714521Z","iopub.status.idle":"2021-05-23T19:19:36.71511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_valid,acc_valid,acc_pix,acc_dice,precision,recall,specificity","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.716291Z","iopub.status.idle":"2021-05-23T19:19:36.716838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image,mask=dataset[2]\nplt.imshow(image.permute(1,2,0))","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.717928Z","iopub.status.idle":"2021-05-23T19:19:36.718461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image,mask=dataset[150]\nplt.imshow(image.permute(1,2,0))","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.719526Z","iopub.status.idle":"2021-05-23T19:19:36.720082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\nwandb.login()\n","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.721234Z","iopub.status.idle":"2021-05-23T19:19:36.721769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef train(network,criterion, optimizer, trainloader):\n    loss_train = 0\n    acc_train = 0\n    network.train()\n    \n    for step in tqdm(range(len(trainloader))):\n\n        images , masks = next(iter(trainloader))\n        \n        # move the images and labels to GPU\n        images = images.to(device)\n        masks = masks.to(device)\n      \n\n        pred = network(images)\n        #pred=torch.sigmoid(pred)\n      \n        # clear all the gradients before calculating them\n        optimizer.zero_grad()\n        #print(masks.shape,images.shape)\n        # find the loss for the current step\n        loss_train_step= criterion(pred , masks)\n        \n        # find accuracy\n        acc_train_ = Metrics(pred,masks)\n        acc_train_step=acc_train_['IoU']\n        # calculate the gradients\n        loss_train_step.backward()\n        #print(loss_train_step,masks.shape)\n        #print(acc_train_)\n        # update the parameters\n        optimizer.step()\n        \n        loss_train += loss_train_step.item()\n        acc_train += acc_train_step  \n            \n    loss_train /= len(trainloader)\n    acc_train /= len(trainloader)\n\n    return loss_train, acc_train,acc_train_  \n        \ndef validate(network,criterion, testloader): \n    loss_valid = 0\n    acc_valid = 0       \n    network.eval()  \n\n    for step in tqdm(range(len(testloader))):\n\n        images , masks = next(iter(testloader))\n        \n        # move the images and labels to GPU\n        images = images.to(device)\n        masks = masks.to(device)\n        \n        \n        pred = network(images)\n        #pred=torch.sigmoid(pred)\n        \n      \n        # clear all the gradients before calculating them\n        optimizer.zero_grad()\n        \n        # find the loss and acc for the current step\n        \n        loss_valid_step = criterion(pred , masks)\n        \n        # find accuracy\n        val_metrics=Metrics(pred,masks)\n        acc_valid_step=val_metrics['IoU']\n     \n        acc_val = val_metrics#Other metrics stored here\n        loss_valid += loss_valid_step.item()\n        acc_valid += acc_valid_step\n        #print(loss_tvalid_step,masks.shape)\n        #print(acc_val)\n\n    loss_valid /= len(testloader)\n    acc_valid /= len(testloader)\n\n    return loss_valid, acc_valid,acc_val","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.722956Z","iopub.status.idle":"2021-05-23T19:19:36.723505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = \"cpu\"\n\nif torch.cuda.is_available():\n    device = \"cuda\"\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.724585Z","iopub.status.idle":"2021-05-23T19:19:36.725196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport wandb\n\nwandb.login()\n","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.726403Z","iopub.status.idle":"2021-05-23T19:19:36.727034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = {'model': model,\n              'state_dict': model.state_dict(),\n              'optimizer' : optimizer.state_dict()}\n\ntorch.save(checkpoint, 'epoch20checkpoint.pth')","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.728235Z","iopub.status.idle":"2021-05-23T19:19:36.728825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dataset)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.729935Z","iopub.status.idle":"2021-05-23T19:19:36.730499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=np.array([2,2,2])\ny=torch.from_numpy(y)#,dtype=torch.torch.float32) \ny=y.to(torch.float32)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.731634Z","iopub.status.idle":"2021-05-23T19:19:36.732193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.dtype","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.733272Z","iopub.status.idle":"2021-05-23T19:19:36.733861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_path = Path('../input/38cloud-cloud-segmentation-in-satellite-images/38-Cloud_training')\ndataset = CloudDataset(base_path/'train_red', \n                    base_path/'train_green', \n                    base_path/'train_blue', \n                    base_path/'train_nir',\n                    base_path/'train_gt',transform=transformations)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.734985Z","iopub.status.idle":"2021-05-23T19:19:36.735524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image,mask=dataset[6000]\nplt.imshow(image.permute(1,2,0))","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.736602Z","iopub.status.idle":"2021-05-23T19:19:36.737213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_length=int(0.50* len(dataset))\n\ntest_length=len(dataset)-train_length\n\n\ntrain_dataset,test_dataset=torch.utils.data.random_split(dataset,(train_length,test_length))\nval_length=250\ntest_length=test_length-250\nval_set,_=torch.utils.data.random_split(test_dataset,(val_length,test_length))\nbatch_size= 12\n\ntrainloader = DataLoader(train_dataset,\n        batch_size=batch_size, shuffle=True,num_workers= 2)\ntestloader = DataLoader(val_set,\n        batch_size=batch_size, shuffle=False,num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.73831Z","iopub.status.idle":"2021-05-23T19:19:36.739046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nwandb.init(name='Clouds', \n           project='Pretrained_UnNet+WeightedBCE_2',\n           notes='RGBNIR', \n           #tags=['Replay-Attack','Cyclic_LR'],\n           entity='creganstark')\n\n# WandB Configurations (optional)        \nwandb.config.lr = 5e-3 \n#model=UNet()\n#model=model.double()\n#model = model.to(device)\n\n#criterion = FocalTverskyLoss()\ncriterion=nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.3053))\noptimizer = optim.Adam(model.parameters(),lr  =  wandb.config.lr)# ,\n                      #momentum     = 0.9,\n                      #nesterov     = True,\n                      #weight_decay = 5e-4)\n\n#scheduler = optim.lr_scheduler.CyclicLR(optimizer,base_lr=wandb.config.lr,max_lr=1e-3 ,step_size_up=2000)\n#scheduler = optim.lr_scheduler.CyclicLR(optimizer,base_lr=wandb.config.lr,max_lr=1e-3 ,step_size_up=2000)\n  \n\n# Log the network weight histograms (optional)\n#wandb.watch(model)\n\nnum_epochs = 5\nstart_time = time.time()\nprev_acc=0\nfor epoch in range(1, num_epochs+1):\n    \n    loss_train, acc_train,metric_train = train(model, criterion, optimizer, trainloader)\n    loss_valid, acc_valid,metric_val = validate(model, criterion, testloader)\n    \n    print('Epoch: {}  Train Loss: {:.4f}  Train IoU: {:.4f}  Valid Loss: {:.4f}  Valid IoU: {:.4f}'.\n          format(epoch, loss_train, acc_train, loss_valid, acc_valid))\n\n    # Log the loss and accuracy values at the end of each epoch\n    wandb.log({\n        \"Epoch\": epoch,\n        \"Train IoU\": metric_train['IoU'],\n        \"Train Dice\": metric_train['Dice'],\n        \"Train Pixel Acc\": metric_train['Pixel_Acc'],\n        \"Train Precision\":metric_train[\"Precision\"],\n        \"Train Recall\": metric_train['Recall'],\n        \"Train Specificity\":metric_train['Specificity'],\n        \"Train Loss\": loss_train,\n        \"Val IoU\": metric_val['IoU'],\n        \"Val Dice \": metric_val['Dice'],\n        \"Val Pixel Acc\": metric_val['Pixel_Acc'],\n        \"Val Precision\":metric_val[\"Precision\"],\n        \"Val Recall\": metric_val['Recall'],\n        \"Val Specificity\":metric_val['Specificity'],\n        \"Val Loss\" : loss_valid\n       })\n    if acc_valid>prev_acc:\n      prev_acc=acc_valid\n      paths = \"model\"+str(acc_valid)+\".pt\"\n      print('Saving Model')\n      torch.save({\n          'epoch': epoch,\n          'model_state_dict': model.state_dict(),\n          'optimizer_state_dict': optimizer.state_dict(),\n          'val_loss': loss_valid,\n          'val_acc':acc_valid,\n          'train_acc':acc_train,\n          'loss_acc':loss_train,\n          }, str(paths))\n\nprint(\"Time Elapsed : {:.4f}s\".format(time.time() - start_time))","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.740191Z","iopub.status.idle":"2021-05-23T19:19:36.740728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion=nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.3053))\noptimizer = optim.Adam(model.parameters(),lr  =  1e-2)# ,\nnum_epochs = 5\nstart_time = time.time()\nprev_acc=0\nfor epoch in range(1, num_epochs+1):\n    \n    loss_train, acc_train,metric_train = train(model, criterion, optimizer, trainloader)\n    loss_valid, acc_valid,metric_val = validate(model, criterion, testloader)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.741773Z","iopub.status.idle":"2021-05-23T19:19:36.74232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Metrics(inputs, targets):\n    \n    inputs = torch.sigmoid(inputs)\n    inputs=inputs.round().int()\n    targets=targets.int()\n    smooth = 1.0\n    inputs = inputs.view(-1)\n    targets = targets.view(-1)\n    intersection = (inputs & targets).float().sum()\n    TP=intersection\n    FP = ((1-targets) & inputs).float().sum()\n    FN = (targets & (1-inputs)).float().sum()\n    TN = ((1-targets) & (1-inputs)).float().sum()\n    total = (inputs + targets).float().sum()\n    union = total - intersection \n    IoU = ((intersection + smooth)/(union + smooth))\n    # 'Dice':dice, 'Pixel_Acc': acc, 'Precision': precision,'Recall': recall, 'Specificity':specificity}\n    #return metrics\n    \n    dice = (2.0 * intersection + smooth) / (total + smooth)\n    IoU = ((intersection + smooth)/(union + smooth))\n    valid = (targets >= 0)\n    acc_sum = (valid * (inputs == targets)).sum()\n    valid_sum = valid.sum()\n    #acc2=(inputs.argmax(dim=1) == targets.float().mean()\n    acc = (float(acc_sum) / (valid_sum + 1e-10))\n    precision = (intersection/(FP+intersection+1e-5))\n    recall = (intersection/(FN+intersection+1e-5))\n    specificity = (TN/(TN+FP+1e-5))\n    metrics={'IoU':IoU,'Dice':dice, 'Pixel_Acc': acc, 'Precision': precision,'Recall': recall, 'Specificity':specificity}\n    return metrics\ndef validate2(network,criterion): \n    train_dataset,test_dataset=torch.utils.data.random_split(dataset,(6000,2400))\n    \n\n    batch_size= 12\n\n    \n    testloader = DataLoader(test_dataset,\n        batch_size=batch_size, shuffle=False,num_workers=2)\n    \n    \n    loss_valid = 0\n    acc_valid = 0    \n    acc_pix = 0\n    acc_dice=0\n    precision=0\n    recall=0\n    specificity=0\n    network.eval()  \n\n    for step in tqdm(range(len(testloader))):\n\n        images , masks = next(iter(testloader))\n        \n        # move the images and labels to GPU\n        images = images.to(device)\n        masks = masks.to(device)\n        \n        \n        pred = network(images)\n        \n        \n        loss_valid_step = criterion(pred , masks)\n       \n        val_metrics=Metrics(pred,masks)\n        \n        #acc_val = val_metrics\n        acc_valid_step=val_metrics['IoU']\n        acc_valid_dice=val_metrics['Dice']\n        acc_valid_pixel=val_metrics['Pixel_Acc']\n        acc_precision=val_metrics['Precision']\n        acc_recall = val_metrics['Recall']\n        acc_speicificity = val_metrics['Specificity']\n        precision+=acc_precision\n        recall+=acc_recall\n        specificity+=acc_speicificity\n        loss_valid += loss_valid_step.item()\n        acc_valid += acc_valid_step\n        acc_pix+=acc_valid_pixel\n        acc_dice+=acc_valid_dice\n        \n        \n        #print(loss_tvalid_step,masks.shape)\n        #print(acc_val)\n\n    loss_valid /= len(testloader)\n    acc_valid /= len(testloader)\n    acc_pix/= len(testloader)\n    acc_dice/= len(testloader) \n    precision/=len(testloader) \n    recall/=len(testloader) \n    specificty/=len(testloader) \n    \n\n    return loss_valid,acc_valid,acc_pix,acc_dice,precision,recall,specificity","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.743466Z","iopub.status.idle":"2021-05-23T19:19:36.744033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_valid,acc_valid,acc_pix,acc_dice,precision,recall,specificity=validate2(model,criterion)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.74517Z","iopub.status.idle":"2021-05-23T19:19:36.745706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paths='finalbce50.pt'\ntorch.save({\n          'epoch': epoch,\n          'model_state_dict': model.state_dict(),\n          'optimizer_state_dict': optimizer.state_dict(),\n          'val_loss': loss_valid,\n          'val_acc':acc_valid,\n          'train_acc':acc_train,\n          'loss_acc':loss_train,\n          }, str(paths))","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.746775Z","iopub.status.idle":"2021-05-23T19:19:36.747325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir(r'/kaggle/working')\nfrom IPython.display import FileLink\nFileLink(r'finalbce50.pt')","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.748402Z","iopub.status.idle":"2021-05-23T19:19:36.748958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#optimizer = 'optimizer_state_dict': optimizer.state_dict()\nfilename='../input/checkpointsures50/25epochsunet50.pt'\ncheckpoint = torch.load(filename)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.750041Z","iopub.status.idle":"2021-05-23T19:19:36.750562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(),lr  = 5e-3)\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.751631Z","iopub.status.idle":"2021-05-23T19:19:36.752191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.753344Z","iopub.status.idle":"2021-05-23T19:19:36.753896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#wandb.init(name='Clouds', \n           #project='Pretrained_UnNet+WeightedBCE_2',\n           #notes='RGBNIR', \n           #tags=['Replay-Attack','Cyclic_LR'],\n           #entity='creganstark')\n\n# WandB Configurations (optional)        \n#wandb.config.lr = 7e-3 \n#model=UNet()\nmodel=model.double()\nmodel = model.to(device)\n\n#criterion = FocalTverskyLoss()\ncriterion=nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.3053))\noptimizer = optim.Adam(model.parameters(),lr  = 0.007 )# ,\n                      #momentum     = 0.9,\n                      #nesterov     = True,\n                      #weight_decay = 5e-4)\n\n#scheduler = optim.lr_scheduler.CyclicLR(optimizer,base_lr=wandb.config.lr,max_lr=1e-3 ,step_size_up=2000)\n#scheduler = optim.lr_scheduler.CyclicLR(optimizer,base_lr=wandb.config.lr,max_lr=1e-3 ,step_size_up=2000)\n  \n\n# Log the network weight histograms (optional)\n#wandb.watch(model)\n\nnum_epochs = 5\nstart_time = time.time()\nprev_acc=0\nfor epoch in range(1, num_epochs+1):\n    \n    loss_train, acc_train,metric_train = train(model, criterion, optimizer, trainloader)\n    loss_valid, acc_valid,metric_val = validate(model, criterion, testloader)\n    \n    print('Epoch: {}  Train Loss: {:.4f}  Train IoU: {:.4f}  Valid Loss: {:.4f}  Valid IoU: {:.4f}'.\n          format(epoch, loss_train, acc_train, loss_valid, acc_valid))\n\n    # Log the loss and accuracy values at the end of each epoch\n    wandb.log({\n        \"Epoch\": epoch,\n        \"Train IoU\": metric_train['IoU'],\n        \"Train Dice\": metric_train['Dice'],\n        \"Train Pixel Acc\": metric_train['Pixel_Acc'],\n        \"Train Precision\":metric_train[\"Precision\"],\n        \"Train Recall\": metric_train['Recall'],\n        \"Train Specificity\":metric_train['Specificity'],\n        \"Train Loss\": loss_train,\n        \"Val IoU\": metric_val['IoU'],\n        \"Val Dice \": metric_val['Dice'],\n        \"Val Pixel Acc\": metric_val['Pixel_Acc'],\n        \"Val Precision\":metric_val[\"Precision\"],\n        \"Val Recall\": metric_val['Recall'],\n        \"Val Specificity\":metric_val['Specificity'],\n        \"Val Loss\" : loss_valid\n       })\n    if acc_valid>prev_acc:\n      prev_acc=acc_valid\n      paths = \"model\"+str(acc_valid)+\".pt\"\n      print('Saving Model')\n      torch.save({\n          'epoch': epoch,\n          'model_state_dict': model.state_dict(),\n          'optimizer_state_dict': optimizer.state_dict(),\n          'val_loss': loss_valid,\n          'val_acc':acc_valid,\n          'train_acc':acc_train,\n          'loss_acc':loss_train,\n          }, str(paths))\n\nprint(\"Time Elapsed : {:.4f}s\".format(time.time() - start_time))","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.755148Z","iopub.status.idle":"2021-05-23T19:19:36.755684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir(r'/kaggle/working')","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.756769Z","iopub.status.idle":"2021-05-23T19:19:36.757342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir(r'/kaggle/working')\nfrom IPython.display import FileLink\nFileLink(r'iou_0.6147.pt')","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.758456Z","iopub.status.idle":"2021-05-23T19:19:36.759089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate2(network,criterion, testloader): \n    loss_valid = 0\n    acc_valid = 0    \n    acc_pix = 0\n    acc_dice=0\n    network.eval()  \n\n    for step in tqdm(range(len(testloader))):\n\n        images , masks = next(iter(testloader))\n        \n        # move the images and labels to GPU\n        images = images.to(device)\n        masks = masks.to(device)\n        \n        \n        pred = network(images)\n        \n        \n        loss_valid_step = criterion(pred , masks)\n       \n        val_metrics=Metrics(pred,masks)\n        \n        #acc_val = val_metrics\n        acc_valid_step=val_metrics['IoU']\n        acc_valid_dice=val_metrics['Dice']\n        acc_valid_pixel=val_metrics['Pixel_Acc']\n        loss_valid += loss_valid_step.item()\n        acc_valid += acc_valid_step\n        acc_pix+=acc_valid_pixel\n        acc_dice+=acc_valid_dice\n        \n        \n        #print(loss_tvalid_step,masks.shape)\n        #print(acc_val)\n\n    loss_valid /= len(testloader)\n    acc_valid /= len(testloader)\n    acc_pix/= len(testloader)\n    acc_dice/= len(testloader)   \n\n    \n\n    return loss_valid,acc_valid,acc_pix,acc_dice","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.76014Z","iopub.status.idle":"2021-05-23T19:19:36.760665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_length=int(0.70* len(dataset))\n\ntest_length=len(dataset)-train_length\n\n\ntrain_dataset,test_dataset=torch.utils.data.random_split(dataset,(train_length,test_length))\n#val_length=300\n#test_length-=300\n#val_set,_=torch.utils.data.random_split(test_dataset,(val_length,test_length))\nbatch_size= 12\n\ntrainloader = DataLoader(train_dataset,\n        batch_size=batch_size, shuffle=True,num_workers= 2)\ntestloader = DataLoader(test_dataset,\n        batch_size=batch_size, shuffle=False,num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.761749Z","iopub.status.idle":"2021-05-23T19:19:36.762297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_length=int(0.90* len(dataset))\n\ntest_length=len(dataset)-train_length\n\n\ntrain_dataset,test_dataset=torch.utils.data.random_split(dataset,(train_length,test_length))\nval_length=200\ntest_length-=200\nval_set,_=torch.utils.data.random_split(test_dataset,(val_length,test_length))\nbatch_size= 12\n\ntrainloader = DataLoader(train_dataset,\n        batch_size=batch_size, shuffle=True,num_workers= 2)\ntestloader = DataLoader(val_set,\n        batch_size=batch_size, shuffle=False,num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.763324Z","iopub.status.idle":"2021-05-23T19:19:36.763875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd ./","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.764985Z","iopub.status.idle":"2021-05-23T19:19:36.765516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#filename = 'modeltensor(0.8413, device='cuda:0').pt\nfilename = 'modeltensor(0.7946, device='+'-cuda'+':'+'0-'+').pt'\nfilename=filename.replace('-',\"'\")\nfilename='../input/checkpointsures50/25epochsunet50.pt'\ncheckpoint = torch.load(filepath)\ndef load_checkpoint(model,filepath):\n    checkpoint = torch.load(filepath)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    #for parameter in model.parameters():\n        #parameter.requires_grad = True\n    return model\nmodel=load_checkpoint(model,filename)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.766696Z","iopub.status.idle":"2021-05-23T19:19:36.767244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_valid, acc_valid,acc_pix,acc_dice = validate(model,criterion, testloader)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.768295Z","iopub.status.idle":"2021-05-23T19:19:36.768836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nwandb.init(name='Clouds', \n           project='Pretrained_UnNet+WeightedBCE_2',\n           notes='RGBNIR', \n           #tags=['Replay-Attack','Cyclic_LR'],\n           entity='creganstark')\n\n# WandB Configurations (optional)        \nwandb.config.lr = 5e-3 \n#model=UNet()\n#model=model.double()\n#model = model.to(device)\n\n#criterion = FocalTverskyLoss()\ncriterion=nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.3053))\noptimizer = optim.Adam(model.parameters(),lr  =  wandb.config.lr)# ,\n                      #momentum     = 0.9,\n                      #nesterov     = True,\n                      #weight_decay = 5e-4)\n\n#scheduler = optim.lr_scheduler.CyclicLR(optimizer,base_lr=wandb.config.lr,max_lr=1e-3 ,step_size_up=2000)\n#scheduler = optim.lr_scheduler.CyclicLR(optimizer,base_lr=wandb.config.lr,max_lr=1e-3 ,step_size_up=2000)\n  \n\n# Log the network weight histograms (optional)\n#wandb.watch(model)\n\nnum_epochs = 5\nstart_time = time.time()\nprev_acc=0\nfor epoch in range(1, num_epochs+1):\n    \n    loss_train, acc_train,metric_train = train(model, criterion, optimizer, trainloader)\n    loss_valid, acc_valid,metric_val = validate(model, criterion, testloader)\n    \n    print('Epoch: {}  Train Loss: {:.4f}  Train IoU: {:.4f}  Valid Loss: {:.4f}  Valid IoU: {:.4f}'.\n          format(epoch, loss_train, acc_train, loss_valid, acc_valid))\n\n    # Log the loss and accuracy values at the end of each epoch\n    wandb.log({\n        \"Epoch\": epoch,\n        \"Train IoU\": metric_train['IoU'],\n        \"Train Dice\": metric_train['Dice'],\n        \"Train Pixel Acc\": metric_train['Pixel_Acc'],\n        \"Train Precision\":metric_train[\"Precision\"],\n        \"Train Recall\": metric_train['Recall'],\n        \"Train Specificity\":metric_train['Specificity'],\n        \"Train Loss\": loss_train,\n        \"Val IoU\": metric_val['IoU'],\n        \"Val Dice \": metric_val['Dice'],\n        \"Val Pixel Acc\": metric_val['Pixel_Acc'],\n        \"Val Precision\":metric_val[\"Precision\"],\n        \"Val Recall\": metric_val['Recall'],\n        \"Val Specificity\":metric_val['Specificity'],\n        \"Val Loss\" : loss_valid\n       })\n    if acc_valid>prev_acc:\n      prev_acc=acc_valid\n      paths = \"model\"+str(acc_valid)+\".pt\"\n      print('Saving Model')\n      torch.save({\n          'epoch': epoch,\n          'model_state_dict': model.state_dict(),\n          'optimizer_state_dict': optimizer.state_dict(),\n          'val_loss': loss_valid,\n          'val_acc':acc_valid,\n          'train_acc':acc_train,\n          'loss_acc':loss_train,\n          }, str(paths))\n\nprint(\"Time Elapsed : {:.4f}s\".format(time.time() - start_time))","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.770075Z","iopub.status.idle":"2021-05-23T19:19:36.770602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_valid, acc_valid,acc_pix,acc_dice = validate(model,criterion, testloader)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.771691Z","iopub.status.idle":"2021-05-23T19:19:36.772236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = 9e-3 \ncriterion=nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.3053))\noptimizer = optim.Adam(model.parameters(),lr  =  lr)# ,\nnum_epochs = 5\nstart_time = time.time()\nprev_acc=0\nfor epoch in range(1, num_epochs+1):\n    \n    loss_train, acc_train,metric_train = train(model, criterion, optimizer, trainloader)\n    loss_valid, acc_valid,metric_val = validate(model, criterion, testloader)\n    \n    print('Epoch: {}  Train Loss: {:.4f}  Train IoU: {:.4f}  Valid Loss: {:.4f}  Valid IoU: {:.4f}'.\n          format(epoch, loss_train, acc_train, loss_valid, acc_valid))","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.773325Z","iopub.status.idle":"2021-05-23T19:19:36.773874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.774983Z","iopub.status.idle":"2021-05-23T19:19:36.77551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_valid, acc_valid,acc_pix,acc_dice","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.776579Z","iopub.status.idle":"2021-05-23T19:19:36.777137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_valid, acc_valid,acc_pix,acc_dice","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.778194Z","iopub.status.idle":"2021-05-23T19:19:36.778743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_valid, acc_valid,acc_pix,acc_dice","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.780041Z","iopub.status.idle":"2021-05-23T19:19:36.780704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_valid, acc_valid,acc_pix,acc_dice","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.781791Z","iopub.status.idle":"2021-05-23T19:19:36.782403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_valid, acc_valid,acc_pix,acc_dice","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.783499Z","iopub.status.idle":"2021-05-23T19:19:36.784084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_valid, acc_valid,metric_val","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.785326Z","iopub.status.idle":"2021-05-23T19:19:36.785882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#filename = 'modeltensor(0.8413, device='cuda:0').pt\nfilename = 'modeltensor(0.7946, device='+'-cuda'+':'+'0-'+').pt'\nfilename=filename.replace('-',\"'\")\n#filename='epoch20checkpoint.pth'\ndef load_checkpoint(model,filepath):\n    checkpoint = torch.load(filepath)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    #for parameter in model.parameters():\n        #parameter.requires_grad = True\n    return model\nmodel=load_checkpoint(model,filename)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.786981Z","iopub.status.idle":"2021-05-23T19:19:36.787514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paths='iou_0.6.pt'\ntorch.save({\n          'epoch': epoch,\n          'model_state_dict': model.state_dict(),\n          'optimizer_state_dict': optimizer.state_dict(),\n          'val_loss': loss_valid,\n          'val_acc':acc_valid,\n          'train_acc':acc_train,\n          'loss_acc':loss_train,\n          }, str(paths))","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.788579Z","iopub.status.idle":"2021-05-23T19:19:36.789145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_valid, acc_valid,metric_val = validate(model,criterion, testloader)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.790247Z","iopub.status.idle":"2021-05-23T19:19:36.790826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_valid, acc_valid,metric_val = validate(model,criterion, testloader)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.791941Z","iopub.status.idle":"2021-05-23T19:19:36.79247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_valid, acc_valid,metric_val","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.793638Z","iopub.status.idle":"2021-05-23T19:19:36.794208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_valid, acc_valid,metric_val","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.795296Z","iopub.status.idle":"2021-05-23T19:19:36.795842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_valid, acc_valid,metric_val = validate(model,criterion, testloader)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.797006Z","iopub.status.idle":"2021-05-23T19:19:36.797544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_valid, acc_valid,metric_val","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.798784Z","iopub.status.idle":"2021-05-23T19:19:36.799335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_valid, acc_valid,metric_val = validate(model,criterion, testloader)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.800549Z","iopub.status.idle":"2021-05-23T19:19:36.801116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_valid, acc_valid,metric_val","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.802178Z","iopub.status.idle":"2021-05-23T19:19:36.802718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_valid, acc_valid,metric_val = validate(model,criterion, testloader)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.803785Z","iopub.status.idle":"2021-05-23T19:19:36.80434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_valid, acc_valid,metric_val","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.805337Z","iopub.status.idle":"2021-05-23T19:19:36.806024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nwandb.init(name='Clouds', \n           project='Pretrained_UnNet+WeightedBCE_2',\n           notes='RGBNIR', \n           #tags=['Replay-Attack','Cyclic_LR'],\n           entity='creganstark')\n\n# WandB Configurations (optional)        \nwandb.config.lr = 5e-3 \n#model=UNet()\n#model=model.double()\n#model = model.to(device)\n\n#criterion = FocalTverskyLoss()\ncriterion=nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.3053))\noptimizer = optim.Adam(model.parameters(),lr  =  wandb.config.lr)# ,\n                      #momentum     = 0.9,\n                      #nesterov     = True,\n                      #weight_decay = 5e-4)\n\n#scheduler = optim.lr_scheduler.CyclicLR(optimizer,base_lr=wandb.config.lr,max_lr=1e-3 ,step_size_up=2000)\n#scheduler = optim.lr_scheduler.CyclicLR(optimizer,base_lr=wandb.config.lr,max_lr=1e-3 ,step_size_up=2000)\n  \n\n# Log the network weight histograms (optional)\n#wandb.watch(model)\n\nnum_epochs = 5\nstart_time = time.time()\nprev_acc=0\nfor epoch in range(1, num_epochs+1):\n    \n    loss_train, acc_train,metric_train = train(model, criterion, optimizer, trainloader)\n    loss_valid, acc_valid,metric_val = validate(model, criterion, testloader)\n    \n    print('Epoch: {}  Train Loss: {:.4f}  Train IoU: {:.4f}  Valid Loss: {:.4f}  Valid IoU: {:.4f}'.\n          format(epoch, loss_train, acc_train, loss_valid, acc_valid))\n\n    # Log the loss and accuracy values at the end of each epoch\n    wandb.log({\n        \"Epoch\": epoch,\n        \"Train IoU\": metric_train['IoU'],\n        \"Train Dice\": metric_train['Dice'],\n        \"Train Pixel Acc\": metric_train['Pixel_Acc'],\n        \"Train Precision\":metric_train[\"Precision\"],\n        \"Train Recall\": metric_train['Recall'],\n        \"Train Specificity\":metric_train['Specificity'],\n        \"Train Loss\": loss_train,\n        \"Val IoU\": metric_val['IoU'],\n        \"Val Dice \": metric_val['Dice'],\n        \"Val Pixel Acc\": metric_val['Pixel_Acc'],\n        \"Val Precision\":metric_val[\"Precision\"],\n        \"Val Recall\": metric_val['Recall'],\n        \"Val Specificity\":metric_val['Specificity'],\n        \"Val Loss\" : loss_valid\n       })\n    if acc_valid>prev_acc:\n      prev_acc=acc_valid\n      paths = \"model\"+str(acc_valid)+\".pt\"\n      print('Saving Model')\n      torch.save({\n          'epoch': epoch,\n          'model_state_dict': model.state_dict(),\n          'optimizer_state_dict': optimizer.state_dict(),\n          'val_loss': loss_valid,\n          'val_acc':acc_valid,\n          'train_acc':acc_train,\n          'loss_acc':loss_train,\n          }, str(paths))\n\nprint(\"Time Elapsed : {:.4f}s\".format(time.time() - start_time))","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.807281Z","iopub.status.idle":"2021-05-23T19:19:36.807829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paths='25epochsunet50'\ntorch.save({\n          'epoch': epoch,\n          'model_state_dict': model.state_dict(),\n          'optimizer_state_dict': optimizer.state_dict(),\n          'val_loss': loss_valid,\n          'val_acc':acc_valid,\n          'train_acc':acc_train,\n          'loss_acc':loss_train,\n          }, str(paths))","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.808939Z","iopub.status.idle":"2021-05-23T19:19:36.809475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename = 'modeltensor(0.8413, device='+'-cuda'+':'+'0-'+').pt'","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.81064Z","iopub.status.idle":"2021-05-23T19:19:36.811207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename = 'modeltensor(0.8413, device='+'-cuda'+':'+'0-'+').pt'\nfilename=filename.replace('-',\"'\")","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.812251Z","iopub.status.idle":"2021-05-23T19:19:36.812805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"./modeltensor(0.8413, device='cuda:0').pt","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.813925Z","iopub.status.idle":"2021-05-23T19:19:36.814453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#filename = 'modeltensor(0.8413, device='cuda:0').pt\n#filename = 'modeltensor(0.8413, device='+'-cuda'+':'+'0-'+').pt'\n#filename=filename.replace('-',\"'\")\nfilename='25epochsunet50'\ndef load_checkpoint(model,filepath):\n    checkpoint = torch.load(filepath)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    #for parameter in model.parameters():\n        #parameter.requires_grad = True\n    return model\nmodel=load_checkpoint(model,filename)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.815641Z","iopub.status.idle":"2021-05-23T19:19:36.816198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_length=int(0.70* len(dataset))\n\ntest_length=len(dataset)-train_length\n\n\ntrain_dataset,test_dataset=torch.utils.data.random_split(dataset,(train_length,test_length))\nval_length=300\ntest_length-=300\nval_set,_=torch.utils.data.random_split(test_dataset,(val_length,test_length))\nbatch_size= 12\n\ntrainloader = DataLoader(train_dataset,\n        batch_size=batch_size, shuffle=True,num_workers= 2)\ntestloader = DataLoader(val_set,\n        batch_size=batch_size, shuffle=False,num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.817273Z","iopub.status.idle":"2021-05-23T19:19:36.817842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nwandb.init(name='Clouds', \n           project='Pretrained_UnNet+WeightedBCE_2',\n           notes='RGBNIR', \n           #tags=['Replay-Attack','Cyclic_LR'],\n           entity='creganstark')\n\n# WandB Configurations (optional)        \nwandb.config.lr = 5e-3 \n#model=UNet()\n#model=model.double()\n#model = model.to(device)\n\n#criterion = FocalTverskyLoss()\ncriterion=nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.3053))\noptimizer = optim.Adam(model.parameters(),lr  =  wandb.config.lr)# ,\n                      #momentum     = 0.9,\n                      #nesterov     = True,\n                      #weight_decay = 5e-4)\n\n#scheduler = optim.lr_scheduler.CyclicLR(optimizer,base_lr=wandb.config.lr,max_lr=1e-3 ,step_size_up=2000)\n#scheduler = optim.lr_scheduler.CyclicLR(optimizer,base_lr=wandb.config.lr,max_lr=1e-3 ,step_size_up=2000)\n  \n\n# Log the network weight histograms (optional)\n#wandb.watch(model)\n\nnum_epochs = 5\nstart_time = time.time()\nprev_acc=0\nfor epoch in range(1, num_epochs+1):\n    \n    loss_train, acc_train,metric_train = train(model, criterion, optimizer, trainloader)\n    loss_valid, acc_valid,metric_val = validate(model, criterion, testloader)\n    \n    print('Epoch: {}  Train Loss: {:.4f}  Train IoU: {:.4f}  Valid Loss: {:.4f}  Valid IoU: {:.4f}'.\n          format(epoch, loss_train, acc_train, loss_valid, acc_valid))\n\n    # Log the loss and accuracy values at the end of each epoch\n    wandb.log({\n        \"Epoch\": epoch,\n        \"Train IoU\": metric_train['IoU'],\n        \"Train Dice\": metric_train['Dice'],\n        \"Train Pixel Acc\": metric_train['Pixel_Acc'],\n        \"Train Precision\":metric_train[\"Precision\"],\n        \"Train Recall\": metric_train['Recall'],\n        \"Train Specificity\":metric_train['Specificity'],\n        \"Train Loss\": loss_train,\n        \"Val IoU\": metric_val['IoU'],\n        \"Val Dice \": metric_val['Dice'],\n        \"Val Pixel Acc\": metric_val['Pixel_Acc'],\n        \"Val Precision\":metric_val[\"Precision\"],\n        \"Val Recall\": metric_val['Recall'],\n        \"Val Specificity\":metric_val['Specificity'],\n        \"Val Loss\" : loss_valid\n       })\n    if acc_valid>prev_acc:\n      prev_acc=acc_valid\n      paths = \"model\"+str(acc_valid)+\".pt\"\n      print('Saving Model')\n      torch.save({\n          'epoch': epoch,\n          'model_state_dict': model.state_dict(),\n          'optimizer_state_dict': optimizer.state_dict(),\n          'val_loss': loss_valid,\n          'val_acc':acc_valid,\n          'train_acc':acc_train,\n          'loss_acc':loss_train,\n          }, str(paths))\n\nprint(\"Time Elapsed : {:.4f}s\".format(time.time() - start_time))","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.819025Z","iopub.status.idle":"2021-05-23T19:19:36.819554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nwandb.init(name='Clouds', \n           project='Pretrained_UnNet+WeightedBCE_2',\n           notes='RGBNIR', \n           #tags=['Replay-Attack','Cyclic_LR'],\n           entity='creganstark')\n\n# WandB Configurations (optional)        \nwandb.config.lr = 5e-3 \n#model=UNet()\n#model=model.double()\n#model = model.to(device)\n\n#criterion = FocalTverskyLoss()\ncriterion=nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.3053))\noptimizer = optim.Adam(model.parameters(),lr  =  wandb.config.lr)# ,\n                      #momentum     = 0.9,\n                      #nesterov     = True,\n                      #weight_decay = 5e-4)\n\n#scheduler = optim.lr_scheduler.CyclicLR(optimizer,base_lr=wandb.config.lr,max_lr=1e-3 ,step_size_up=2000)\n#scheduler = optim.lr_scheduler.CyclicLR(optimizer,base_lr=wandb.config.lr,max_lr=1e-3 ,step_size_up=2000)\n  \n\n# Log the network weight histograms (optional)\n#wandb.watch(model)\n\nnum_epochs = 5\nstart_time = time.time()\nprev_acc=0\nfor epoch in range(1, num_epochs+1):\n    \n    loss_train, acc_train,metric_train = train(model, criterion, optimizer, trainloader)\n    loss_valid, acc_valid,metric_val = validate(model, criterion, testloader)\n    \n    print('Epoch: {}  Train Loss: {:.4f}  Train IoU: {:.4f}  Valid Loss: {:.4f}  Valid IoU: {:.4f}'.\n          format(epoch, loss_train, acc_train, loss_valid, acc_valid))\n\n    # Log the loss and accuracy values at the end of each epoch\n    wandb.log({\n        \"Epoch\": epoch,\n        \"Train IoU\": metric_train['IoU'],\n        \"Train Dice\": metric_train['Dice'],\n        \"Train Pixel Acc\": metric_train['Pixel_Acc'],\n        \"Train Precision\":metric_train[\"Precision\"],\n        \"Train Recall\": metric_train['Recall'],\n        \"Train Specificity\":metric_train['Specificity'],\n        \"Train Loss\": loss_train,\n        \"Val IoU\": metric_val['IoU'],\n        \"Val Dice \": metric_val['Dice'],\n        \"Val Pixel Acc\": metric_val['Pixel_Acc'],\n        \"Val Precision\":metric_val[\"Precision\"],\n        \"Val Recall\": metric_val['Recall'],\n        \"Val Specificity\":metric_val['Specificity'],\n        \"Val Loss\" : loss_valid\n       })\n    if acc_valid>prev_acc:\n      prev_acc=acc_valid\n      paths = \"model\"+str(acc_valid)+\".pt\"\n      print('Saving Model')\n      torch.save({\n          'epoch': epoch,\n          'model_state_dict': model.state_dict(),\n          'optimizer_state_dict': optimizer.state_dict(),\n          'val_loss': loss_valid,\n          'val_acc':acc_valid,\n          'train_acc':acc_train,\n          'loss_acc':loss_train,\n          }, str(paths))\n\nprint(\"Time Elapsed : {:.4f}s\".format(time.time() - start_time))","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.820756Z","iopub.status.idle":"2021-05-23T19:19:36.82131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nwandb.init(name='Clouds', \n           project='Pretrained_UnNet+WeightedBCE',\n           notes='RGBNIR', \n           #tags=['Replay-Attack','Cyclic_LR'],\n           entity='creganstark')\n\n# WandB Configurations (optional)        \nwandb.config.lr = 7e-3 \n#model=UNet()\n#model=model.double()\n#model = model.to(device)\n\n#criterion = FocalTverskyLoss()\ncriterion=nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.3053))\noptimizer = optim.Adam(model.parameters(),lr  =  wandb.config.lr)# ,\n                      #momentum     = 0.9,\n                      #nesterov     = True,\n                      #weight_decay = 5e-4)\n\n#scheduler = optim.lr_scheduler.CyclicLR(optimizer,base_lr=wandb.config.lr,max_lr=1e-3 ,step_size_up=2000)\n#scheduler = optim.lr_scheduler.CyclicLR(optimizer,base_lr=wandb.config.lr,max_lr=1e-3 ,step_size_up=2000)\n  \n\n# Log the network weight histograms (optional)\n#wandb.watch(model)\n\nnum_epochs = 20\nstart_time = time.time()\nprev_acc=0\nfor epoch in range(1, num_epochs+1):\n    \n    loss_train, acc_train,metric_train = train(model, criterion, optimizer, trainloader)\n    loss_valid, acc_valid,metric_val = validate(model, criterion, testloader)\n    \n    print('Epoch: {}  Train Loss: {:.4f}  Train IoU: {:.4f}  Valid Loss: {:.4f}  Valid IoU: {:.4f}'.\n          format(epoch, loss_train, acc_train, loss_valid, acc_valid))\n\n    # Log the loss and accuracy values at the end of each epoch\n    wandb.log({\n        \"Epoch\": epoch,\n        \"Train IoU\": metric_train['IoU'],\n        \"Train Dice\": metric_train['Dice'],\n        \"Train Pixel Acc\": metric_train['Pixel_Acc'],\n        \"Train Precision\":metric_train[\"Precision\"],\n        \"Train Recall\": metric_train['Recall'],\n        \"Train Specificity\":metric_train['Specificity'],\n        \"Train Loss\": loss_train,\n        \"Val IoU\": metric_val['IoU'],\n        \"Val Dice \": metric_val['Dice'],\n        \"Val Pixel Acc\": metric_val['Pixel_Acc'],\n        \"Val Precision\":metric_val[\"Precision\"],\n        \"Val Recall\": metric_val['Recall'],\n        \"Val Specificity\":metric_val['Specificity'],\n        \"Val Loss\" : loss_valid\n       })\n    if acc_valid>prev_acc:\n      prev_acc=acc_valid\n      paths = \"model\"+str(acc_valid)+\".pt\"\n      print('Saving Model')\n      torch.save({\n          'epoch': epoch,\n          'model_state_dict': model.state_dict(),\n          'optimizer_state_dict': optimizer.state_dict(),\n          'val_loss': loss_valid,\n          'val_acc':acc_valid,\n          'train_acc':acc_train,\n          'loss_acc':loss_train,\n          }, str(paths))\n\nprint(\"Time Elapsed : {:.4f}s\".format(time.time() - start_time))","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.822468Z","iopub.status.idle":"2021-05-23T19:19:36.823047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nwandb.init(name='Clouds', \n           project='Pretrained_UnNet+WeightedBCE',\n           notes='RGBNIR', \n           #tags=['Replay-Attack','Cyclic_LR'],\n           entity='creganstark')\n\n# WandB Configurations (optional)        \nwandb.config.lr = 7e-3 \n#model=UNet()\n#model=model.double()\n#model = model.to(device)\n\n#criterion = FocalTverskyLoss()\ncriterion=nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.3053))\noptimizer = optim.Adam(model.parameters(),lr  =  wandb.config.lr)# ,\n                      #momentum     = 0.9,\n                      #nesterov     = True,\n                      #weight_decay = 5e-4)\n\n#scheduler = optim.lr_scheduler.CyclicLR(optimizer,base_lr=wandb.config.lr,max_lr=1e-3 ,step_size_up=2000)\n#scheduler = optim.lr_scheduler.CyclicLR(optimizer,base_lr=wandb.config.lr,max_lr=1e-3 ,step_size_up=2000)\n  \n\n# Log the network weight histograms (optional)\n#wandb.watch(model)\n\nnum_epochs = 20\nstart_time = time.time()\nprev_acc=0\nfor epoch in range(1, num_epochs+1):\n    \n    loss_train, acc_train,metric_train = train(model, criterion, optimizer, trainloader)\n    loss_valid, acc_valid,metric_val = validate(model, criterion, testloader)\n    \n    print('Epoch: {}  Train Loss: {:.4f}  Train IoU: {:.4f}  Valid Loss: {:.4f}  Valid IoU: {:.4f}'.\n          format(epoch, loss_train, acc_train, loss_valid, acc_valid))\n\n    # Log the loss and accuracy values at the end of each epoch\n    wandb.log({\n        \"Epoch\": epoch,\n        \"Train IoU\": metric_train['IoU'],\n        \"Train Dice\": metric_train['Dice'],\n        \"Train Pixel Acc\": metric_train['Pixel_Acc'],\n        \"Train Precision\":metric_train[\"Precision\"],\n        \"Train Recall\": metric_train['Recall'],\n        \"Train Specificity\":metric_train['Specificity'],\n        \"Train Loss\": loss_train,\n        \"Val IoU\": metric_val['IoU'],\n        \"Val Dice \": metric_val['Dice'],\n        \"Val Pixel Acc\": metric_val['Pixel_Acc'],\n        \"Val Precision\":metric_val[\"Precision\"],\n        \"Val Recall\": metric_val['Recall'],\n        \"Val Specificity\":metric_val['Specificity'],\n        \"Val Loss\" : loss_valid\n       })\n    if acc_valid>prev_acc:\n      prev_acc=acc_valid\n      paths = \"model\"+str(acc_valid)+\".pt\"\n      print('Saving Model')\n      torch.save({\n          'epoch': epoch,\n          'model_state_dict': model.state_dict(),\n          'optimizer_state_dict': optimizer.state_dict(),\n          'val_loss': loss_valid,\n          'val_acc':acc_valid,\n          'train_acc':acc_train,\n          'loss_acc':loss_train,\n          }, str(paths))\n\nprint(\"Time Elapsed : {:.4f}s\".format(time.time() - start_time))","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.824213Z","iopub.status.idle":"2021-05-23T19:19:36.824755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images,labels=(next(iter(trainloader)))\nimages = images.to(device)\nlabels = masks.to(device)\npred = network(images)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.825798Z","iopub.status.idle":"2021-05-23T19:19:36.826342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2021-05-23T19:19:36.827405Z","iopub.status.idle":"2021-05-23T19:19:36.828004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}