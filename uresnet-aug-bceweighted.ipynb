{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport wandb\nimport time\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport torchvision\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport albumentations as A\nimport torch.optim as optim\nfrom PIL import Image\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom pathlib import Path\nfrom albumentations.pytorch import ToTensorV2\nimport torch.nn.functional as F\nfrom tqdm.auto import tqdm","metadata":{"execution":{"iopub.status.busy":"2021-05-23T05:42:22.862177Z","iopub.execute_input":"2021-05-23T05:42:22.862620Z","iopub.status.idle":"2021-05-23T05:42:26.678465Z","shell.execute_reply.started":"2021-05-23T05:42:22.862534Z","shell.execute_reply":"2021-05-23T05:42:26.677686Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"original_height=384\noriginal_width =384\n#original_height=224\n#original_width =224\n\ntransformations = A.Compose([\n    #A.Resize(224,224),\n    A.OneOf([\n        A.RandomSizedCrop(min_max_height=(50, 101), height=original_height, width=original_width, p=0.5),\n        A.PadIfNeeded(min_height=original_height, min_width=original_width, p=0.5)\n    ], p=1),    \n    A.VerticalFlip(p=0.5),              \n    A.RandomRotate90(p=0.5),\n    A.OneOf([\n        A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03, p=0.5),\n        A.GridDistortion(p=0.5),\n        A.OpticalDistortion(distort_limit=2, shift_limit=0.5, p=1)                  \n        ], p=0.8),\n    #A.CLAHE(p=0.8),\n    #A.RandomBrightnessContrast(p=0.8),    \n    A.RandomGamma(p=0.8),\n    ])\nclass CloudDataset(Dataset):\n    def __init__(self, r_dir, g_dir, b_dir, nir_dir, gt_dir, pytorch=True,transform=False):\n        super().__init__()\n        \n        # Loop through the files in red folder and combine, into a dictionary, the other bands\n        self.files = [self.combine_files(f, g_dir, b_dir, nir_dir, gt_dir) for f in r_dir.iterdir() if not f.is_dir()]\n        self.pytorch = pytorch\n        self.transform = transform\n        \n    def combine_files(self, r_file: Path, g_dir, b_dir,nir_dir, gt_dir):\n        \n        files = {'red': r_file, \n                 'green':g_dir/r_file.name.replace('red', 'green'),\n                 'blue': b_dir/r_file.name.replace('red', 'blue'), \n                 'nir': nir_dir/r_file.name.replace('red', 'nir'),\n                 'gt': gt_dir/r_file.name.replace('red', 'gt')}\n\n        return files\n                                       \n    def __len__(self):\n        \n        return len(self.files)\n     \n    def open_as_array(self, idx, invert=False, include_nir=True):\n\n        raw_rgb = np.stack([np.array(Image.open(self.files[idx]['red'])),\n                            np.array(Image.open(self.files[idx]['green'])),\n                            np.array(Image.open(self.files[idx]['blue'])),\n                           ], axis=2)\n    \n        if include_nir:\n            nir = np.expand_dims(np.array(Image.open(self.files[idx]['nir'])), 2)\n            raw_rgb = np.concatenate([nir,raw_rgb], axis=2)\n    \n        if invert:\n            raw_rgb = raw_rgb.transpose((2,0,1))\n    \n        # normalize\n        return (raw_rgb / np.iinfo(raw_rgb.dtype).max)\n    \n\n    def open_mask(self, idx, add_dims=False):\n        \n        raw_mask = np.array(Image.open(self.files[idx]['gt']))\n        raw_mask = np.where(raw_mask==255, 1, 0)\n        \n        return np.expand_dims(raw_mask, 0) if add_dims else raw_mask\n    \n    def __getitem__(self, idx):\n                    \n        x = self.open_as_array(idx, invert=False, include_nir=True)\n        \n        y = self.open_mask(idx, add_dims=False)\n       \n        if self.transform is not None:\n            augmented = self.transform(image=x,mask=y)\n            x=augmented['image']#,dtype=torch.float64)\n            y=augmented['mask']#dtype=torch.torch.float32) \n            \n        x=torch.from_numpy(x)#,dtype=torch.float64)\n        y=torch.tensor(y,dtype=torch.float32) \n        x = x.permute(2,0,1)\n        #y=torch.tensor(y,dtype=torch.float32)\n        \n        return x.double(), y.unsqueeze(0)\n    \n    def open_as_pil(self, idx):\n        \n        arr = 256*self.open_as_array(idx)\n        \n        return Image.fromarray(arr.astype(np.uint8), 'RGB')\n    \n    def __repr__(self):\n        s = 'Dataset class with {} files'.format(self.__len__())\n\n        return s","metadata":{"execution":{"iopub.status.busy":"2021-05-23T05:47:41.568063Z","iopub.execute_input":"2021-05-23T05:47:41.568433Z","iopub.status.idle":"2021-05-23T05:47:41.594374Z","shell.execute_reply.started":"2021-05-23T05:47:41.568381Z","shell.execute_reply":"2021-05-23T05:47:41.591788Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"base_path = Path('../input/38cloud-cloud-segmentation-in-satellite-images/38-Cloud_training')\ndataset = CloudDataset(base_path/'train_red', \n                    base_path/'train_green', \n                    base_path/'train_blue', \n                    base_path/'train_nir',\n                    base_path/'train_gt',transform=transformations)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-23T05:47:43.995980Z","iopub.execute_input":"2021-05-23T05:47:43.996325Z","iopub.status.idle":"2021-05-23T05:47:47.916605Z","shell.execute_reply.started":"2021-05-23T05:47:43.996293Z","shell.execute_reply":"2021-05-23T05:47:47.915821Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_length=int(0.712* len(dataset))\n\ntest_length=len(dataset)-train_length\n#val_length=500\n\ntrain_dataset,test_dataset=torch.utils.data.random_split(dataset,(train_length,test_length))\n#test_length=test_length-500\n#val_set,_=torch.utils.data.random_split(test_dataset,(val_length,test_length))\nbatch_size= 12\n\ntrainloader = DataLoader(train_dataset,\n        batch_size=batch_size, shuffle=True,num_workers= 2)\ntestloader = DataLoader(test_dataset,\n        batch_size=batch_size, shuffle=False,num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T05:47:52.530439Z","iopub.execute_input":"2021-05-23T05:47:52.530769Z","iopub.status.idle":"2021-05-23T05:47:52.542531Z","shell.execute_reply.started":"2021-05-23T05:47:52.530739Z","shell.execute_reply":"2021-05-23T05:47:52.541487Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def Metrics(inputs, targets):\n    \n    inputs = torch.sigmoid(inputs)\n    inputs=inputs.round().int()\n    targets=targets.int()\n    smooth = 1.0\n    inputs = inputs.view(-1)\n    targets = targets.view(-1)\n    intersection = (inputs & targets).float().sum()\n    TP=intersection\n    FP = ((1-targets) & inputs).float().sum()\n    FN = (targets & (1-inputs)).float().sum()\n    TN = ((1-targets) & (1-inputs)).float().sum()\n    total = (inputs + targets).float().sum()\n    union = total - intersection \n    dice = (2.0 * intersection + smooth) / (total + smooth)\n    IoU = ((intersection + smooth)/(union + smooth))\n    valid = (targets >= 0)\n    acc_sum = (valid * (inputs == targets)).sum()\n    valid_sum = valid.sum()\n    #acc2=(inputs.argmax(dim=1) == targets.float().mean()\n    acc = (float(acc_sum) / (valid_sum + 1e-10))\n    precision = (intersection/(FP+intersection+1e-5))\n    recall = (intersection/(FN+intersection+1e-5))\n    specificity = (TN/(TN+FP+1e-5))\n    metrics={'IoU':IoU, 'Dice':dice, 'Pixel_Acc': acc, 'Precision': precision,'Recall': recall, 'Specificity':specificity}\n    return metrics\n","metadata":{"execution":{"iopub.status.busy":"2021-05-23T05:42:42.766191Z","iopub.execute_input":"2021-05-23T05:42:42.766516Z","iopub.status.idle":"2021-05-23T05:42:42.777450Z","shell.execute_reply.started":"2021-05-23T05:42:42.766479Z","shell.execute_reply":"2021-05-23T05:42:42.776429Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def train(network,criterion, optimizer, trainloader):\n    loss_train = 0\n    acc_train = 0\n    network.train()\n    \n    for step in tqdm(range(len(trainloader))):\n\n        images , masks = next(iter(trainloader))\n        \n        # move the images and labels to GPU\n        images = images.to(device)\n        masks = masks.to(device)\n      \n\n        pred = network(images)\n        \n      \n        # clear all the gradients before calculating them\n        optimizer.zero_grad()\n        #v_pix=val_metrics['Pixel_Acc']\n        #val_dice = val_metrics['Dice']\n        # find the loss for the current step\n        loss_train_step = criterion(pred , masks)\n        \n        # find accuracy\n        acc_train_ = Metrics(pred,masks)\n        acc_train_step=acc_train_['IoU']\n        # calculate the gradients\n        loss_train_step.backward()\n        \n        # update the parameters\n        optimizer.step()\n        \n        loss_train += loss_train_step.item()\n        acc_train += acc_train_step  \n            \n    loss_train /= len(trainloader)\n    acc_train /= len(trainloader)\n    #gtrain_dice/= len(testloader)\n    #gtrain_pix/= len(testloader)\n    #print(pred.max(),pred.min(),masks.max(),masks.min())\n    return loss_train, acc_train,acc_train_  \n        \ndef validate(network,criterion, testloader): \n    loss_valid = 0\n    acc_valid = 0\n    gval_dice=0\n    gval_pix=0\n    network.eval()  \n\n    for step in tqdm(range(len(testloader))):\n\n        images , masks = next(iter(testloader))\n        \n        # move the images and labels to GPU\n        images = images.to(device)\n        masks = masks.to(device)\n        \n        \n        pred = network(images)\n        #pred=torch.sigmoid(pred)\n        \n      \n        # clear all the gradients before calculating them\n        optimizer.zero_grad()\n        \n        # find the loss and acc for the current step\n        \n        loss_valid_step = criterion(pred , masks)\n        \n        # find accuracy\n        val_metrics=Metrics(pred,masks)\n        acc_valid_step=val_metrics['IoU']\n        #val_pix=val_metrics['Pixel_Acc']\n        #val_dice = val_metrics['Dice']\n        # calculate the gradients\n        #loss_train_step.backward()\n        #print(loss_train_step,masks.shape)\n        #print(acc_train_)\n        # update the parameters\n        #optimizer.step()\n        \n        acc_val = val_metrics\n       # acc_valid_step=acc_val['IoU']\n        loss_valid += loss_valid_step.item()\n        acc_valid += acc_valid_step\n        \n        \n        #print(loss_tvalid_step,masks.shape)\n        #print(acc_val)\n\n    loss_valid /= len(testloader)\n    acc_valid /= len(testloader)\n    #gval_dice/= len(testloader)\n    #gval_pix/= len(testloader)\n    #print(pred.max(),pred.min(),masks.max(),masks.min())\n    return loss_valid, acc_valid,acc_val","metadata":{"execution":{"iopub.status.busy":"2021-05-23T05:42:44.098130Z","iopub.execute_input":"2021-05-23T05:42:44.098564Z","iopub.status.idle":"2021-05-23T05:42:44.108845Z","shell.execute_reply.started":"2021-05-23T05:42:44.098521Z","shell.execute_reply":"2021-05-23T05:42:44.107961Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"!pip install segmentation_models_pytorch \nimport segmentation_models_pytorch as smp\n\nmodel = smp.Unet(\n    encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7,     # use `imagenet` pre-trained weights for encoder initialization\n    in_channels=4,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n    classes=1,                      # model output channels (number of classes in your dataset)\n)\n\n#mask=torch.randn(4,1,384,384)\n#target=torch.randn(4,1,384,384)\n\n\n#z=m(target,mask)\ndevice = \"cpu\"\n\nif torch.cuda.is_available():\n    device = \"cuda\"\n\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T05:42:48.402095Z","iopub.execute_input":"2021-05-23T05:42:48.402419Z","iopub.status.idle":"2021-05-23T05:43:02.152739Z","shell.execute_reply.started":"2021-05-23T05:42:48.402371Z","shell.execute_reply":"2021-05-23T05:43:02.151963Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Collecting segmentation_models_pytorch\n  Downloading segmentation_models_pytorch-0.1.3-py3-none-any.whl (66 kB)\n\u001b[K     |████████████████████████████████| 66 kB 594 kB/s eta 0:00:01\n\u001b[?25hCollecting pretrainedmodels==0.7.4\n  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n\u001b[K     |████████████████████████████████| 58 kB 1.8 MB/s eta 0:00:01\n\u001b[?25hCollecting efficientnet-pytorch==0.6.3\n  Downloading efficientnet_pytorch-0.6.3.tar.gz (16 kB)\nCollecting timm==0.3.2\n  Downloading timm-0.3.2-py3-none-any.whl (244 kB)\n\u001b[K     |████████████████████████████████| 244 kB 3.0 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: torchvision>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from segmentation_models_pytorch) (0.8.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet-pytorch==0.6.3->segmentation_models_pytorch) (1.7.0)\nRequirement already satisfied: munch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (2.5.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (4.56.2)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.6.3->segmentation_models_pytorch) (0.18.2)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.6.3->segmentation_models_pytorch) (3.7.4.3)\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.6.3->segmentation_models_pytorch) (0.6)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.6.3->segmentation_models_pytorch) (1.19.5)\nRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.3.0->segmentation_models_pytorch) (7.2.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from munch->pretrainedmodels==0.7.4->segmentation_models_pytorch) (1.15.0)\nBuilding wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-py3-none-any.whl size=12419 sha256=a827aa5fa06f7493b9fdea9f8eed3c60d6b5986f62595ef7d3ad2a9ecbcd5ebd\n  Stored in directory: /root/.cache/pip/wheels/90/6b/0c/f0ad36d00310e65390b0d4c9218ae6250ac579c92540c9097a\n  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60963 sha256=7adb54dda3a51b550ab00b6c25d6f2d1a86da5e48e72f1acac1aeaf1b2e1a052\n  Stored in directory: /root/.cache/pip/wheels/ed/27/e8/9543d42de2740d3544db96aefef63bda3f2c1761b3334f4873\nSuccessfully built efficientnet-pytorch pretrainedmodels\nInstalling collected packages: timm, pretrainedmodels, efficientnet-pytorch, segmentation-models-pytorch\nSuccessfully installed efficientnet-pytorch-0.6.3 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.1.3 timm-0.3.2\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/83.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b54cc3d478a241499356158cac97c615"}},"metadata":{}},{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"wandb.init(name='Clouds', \n           project='UNetResnet+WBCE+Augs',\n           notes='RGBNIR', \n           #tags=['Replay-Attack','Cyclic_LR'],\n           entity='creganstark')\n\n# WandB Configurations (optional)        \nwandb.config.lr = 7e-3\n#model=model.float()\n#model=model.double()\n#model = model.to(device)\n\ncriterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.3053))\n#criterion = FocalLoss()\noptimizer = optim.Adam(model.parameters(),lr  =  wandb.config.lr)# ,\n                      #momentum     = 0.9,\n                      #nesterov     = True,\n                      #weight_decay = 5e-4)\n\n#scheduler = optim.lr_scheduler.CyclicLR(optimizer,base_lr=wandb.config.lr,max_lr=1e-3 ,step_size_up=2000)\n#scheduler = optim.lr_scheduler.CyclicLR(optimizer,base_lr=wandb.config.lr,max_lr=1e-3 ,step_size_up=2000)\n  \n\n# Log the network weight histograms (optional)\nwandb.watch(model)\n\nnum_epochs = 20\nstart_time = time.time()\nprev_acc=0\nfor epoch in range(1, num_epochs+1):\n    \n    loss_train, acc_train,metric_train = train(model, criterion, optimizer, trainloader)\n    loss_valid, acc_valid,metric_val = validate(model, criterion, testloader)\n    \n    print('Epoch: {}  Train Loss: {:.4f}  Train IoU: {:.4f}  Valid Loss: {:.4f}  Valid IoU: {:.4f}'.\n          format(epoch, loss_train, acc_train, loss_valid, acc_valid))\n    print('Train Metrics',metric_train)\n    print('Val. Metrics',metric_val)\n\n    # Log the loss and accuracy values at the end of each epoch\n    wandb.log({\n        \"Epoch\": epoch,\n        \"Train IoU\": metric_train['IoU'],\n        \"Train Dice\": metric_train['Dice'],\n        \"Train Pixel Acc\": metric_train['Pixel_Acc'],\n        \"Train Precision\":metric_train[\"Precision\"],\n        \"Train Recall\": metric_train['Recall'],\n        \"Train Specificity\":metric_train['Specificity'],\n        \"Train Loss\": loss_train,\n        \"Val IoU\": metric_val['IoU'],\n        \"Val Dice \": metric_val['Dice'],\n        \"Val Pixel Acc\": metric_val['Pixel_Acc'],\n        \"Val Precision\":metric_val[\"Precision\"],\n        \"Val Recall\": metric_val['Recall'],\n        \"Val Specificity\":metric_val['Specificity'],\n        \"Val Loss\" : loss_valid\n       })\n    if acc_valid>prev_acc:\n      prev_acc=acc_valid\n      paths = \"model\"+str(acc_valid)+\".pt\"\n      print('Saving Model')\n      torch.save({\n          'epoch': epoch,\n          'model_state_dict': model.state_dict(),\n          'optimizer_state_dict': optimizer.state_dict(),\n          'val_loss': loss_valid,\n          'val_acc':acc_valid,\n          'train_acc':acc_train,\n          'loss_acc':loss_train,\n          }, str(paths))\n\nprint(\"Time Elapsed : {:.4f}s\".format(time.time() - start_time))","metadata":{"execution":{"iopub.status.busy":"2021-05-23T05:48:06.280537Z","iopub.execute_input":"2021-05-23T05:48:06.280854Z","iopub.status.idle":"2021-05-23T09:24:31.265612Z","shell.execute_reply.started":"2021-05-23T05:48:06.280824Z","shell.execute_reply":"2021-05-23T09:24:31.262926Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:m3ya1nvf) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 331<br/>Program ended successfully."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find user logs for this run at: <code>/kaggle/working/wandb/run-20210523_054556-m3ya1nvf/logs/debug.log</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find internal logs for this run at: <code>/kaggle/working/wandb/run-20210523_054556-m3ya1nvf/logs/debug-internal.log</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    <br/>Synced <strong style=\"color:#cdcd00\">Clouds</strong>: <a href=\"https://wandb.ai/creganstark/UNetResnet%2BWBCE%2BAugs/runs/m3ya1nvf\" target=\"_blank\">https://wandb.ai/creganstark/UNetResnet%2BWBCE%2BAugs/runs/m3ya1nvf</a><br/>\n                "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"...Successfully finished last run (ID:m3ya1nvf). Initializing new run:<br/><br/>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                Tracking run with wandb version 0.10.23<br/>\n                Syncing run <strong style=\"color:#cdcd00\">Clouds</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/creganstark/UNetResnet%2BWBCE%2BAugs\" target=\"_blank\">https://wandb.ai/creganstark/UNetResnet%2BWBCE%2BAugs</a><br/>\n                Run page: <a href=\"https://wandb.ai/creganstark/UNetResnet%2BWBCE%2BAugs/runs/243jzkno\" target=\"_blank\">https://wandb.ai/creganstark/UNetResnet%2BWBCE%2BAugs/runs/243jzkno</a><br/>\n                Run data is saved locally in <code>/kaggle/working/wandb/run-20210523_054806-243jzkno</code><br/><br/>\n            "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/499 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4db3986bec7d490bbb8f1de4a82226aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5aeeee65205a4ba78110fab0cc49b36f"}},"metadata":{}},{"name":"stdout","text":"Epoch: 1  Train Loss: 0.5199  Train IoU: 0.5891  Valid Loss: 0.2847  Valid IoU: 0.7792\nSaving Model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/499 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bcc6f02c74942c182be7924e51809c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc8a406a03b74035b587495c4eaac558"}},"metadata":{}},{"name":"stdout","text":"Epoch: 2  Train Loss: 0.4577  Train IoU: 0.6107  Valid Loss: 0.4382  Valid IoU: 0.7997\nSaving Model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/499 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b23222751e2e426dbe8587511a4ef2fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dceeff6f59cf4f748399cd9685943ce9"}},"metadata":{}},{"name":"stdout","text":"Epoch: 3  Train Loss: 0.4290  Train IoU: 0.6239  Valid Loss: 0.3488  Valid IoU: 0.6702\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/499 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8dcf4b60707409fac130bb9f2d9b548"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39f1229642bf476faf0e80f5cc512244"}},"metadata":{}},{"name":"stdout","text":"Epoch: 4  Train Loss: 0.4179  Train IoU: 0.6312  Valid Loss: 0.1707  Valid IoU: 0.8623\nSaving Model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/499 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48af4cd7efcc4e5eae3dfdd2ec27bd3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef42f39fbf464b0ebc14a6067e394c6a"}},"metadata":{}},{"name":"stdout","text":"Epoch: 5  Train Loss: 0.4200  Train IoU: 0.6175  Valid Loss: 0.2196  Valid IoU: 0.8481\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/499 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49a80a7becd04150adfe91e62aad0e4e"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fae6614f8c0>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n    self._shutdown_workers()\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 140, in join\n    res = self._popen.wait(timeout)\n  File \"/opt/conda/lib/python3.7/multiprocessing/popen_fork.py\", line 45, in wait\n    if not wait([self.sentinel], timeout):\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 921, in wait\n    ready = selector.select(timeout)\n  File \"/opt/conda/lib/python3.7/selectors.py\", line 415, in select\n    fd_event_list = self._selector.poll(timeout)\nKeyboardInterrupt: \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-08cc589ca9cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mloss_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetric_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mloss_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetric_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-2a354b2e0d76>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(network, criterion, optimizer, trainloader)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# move the images and labels to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"len(val_set)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T09:38:13.826756Z","iopub.execute_input":"2021-05-23T09:38:13.827070Z","iopub.status.idle":"2021-05-23T09:38:13.832244Z","shell.execute_reply.started":"2021-05-23T09:38:13.827042Z","shell.execute_reply":"2021-05-23T09:38:13.831411Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"350"},"metadata":{}}]},{"cell_type":"code","source":"wandb.init(name='Clouds', \n           project='UNetResnet+WBCE+Augs',\n           notes='RGBNIR', \n           #tags=['Replay-Attack','Cyclic_LR'],\n           entity='creganstark')\n\n# WandB Configurations (optional)        \nwandb.config.lr = 9e-3\n#model=model.float()\n#model=model.double()\n#model = model.to(device)\n\ncriterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.3053))\n#criterion = FocalLoss()\noptimizer = optim.Adam(model.parameters(),lr  =  wandb.config.lr)# ,\n                      #momentum     = 0.9,\n                      #nesterov     = True,\n                      #weight_decay = 5e-4)\n\n#scheduler = optim.lr_scheduler.CyclicLR(optimizer,base_lr=wandb.config.lr,max_lr=1e-3 ,step_size_up=2000)\n#scheduler = optim.lr_scheduler.CyclicLR(optimizer,base_lr=wandb.config.lr,max_lr=1e-3 ,step_size_up=2000)\n  \n\n# Log the network weight histograms (optional)\n#wandb.watch(model)\n\nnum_epochs = 5\nstart_time = time.time()\nprev_acc=0\nfor epoch in range(1, num_epochs+1):\n    \n    loss_train, acc_train,metric_train = train(model, criterion, optimizer, trainloader)\n    loss_valid, acc_valid,metric_val = validate(model, criterion, testloader)\n    \n    print('Epoch: {}  Train Loss: {:.4f}  Train IoU: {:.4f}  Valid Loss: {:.4f}  Valid IoU: {:.4f}'.\n          format(epoch, loss_train, acc_train, loss_valid, acc_valid))\n    print('Train Metrics',metric_train)\n    print('Val. Metrics',metric_val)\n\n    # Log the loss and accuracy values at the end of each epoch\n    wandb.log({\n        \"Epoch\": epoch,\n        \"Train IoU\": metric_train['IoU'],\n        \"Train Dice\": metric_train['Dice'],\n        \"Train Pixel Acc\": metric_train['Pixel_Acc'],\n        \"Train Precision\":metric_train[\"Precision\"],\n        \"Train Recall\": metric_train['Recall'],\n        \"Train Specificity\":metric_train['Specificity'],\n        \"Train Loss\": loss_train,\n        \"Val IoU\": metric_val['IoU'],\n        \"Val Dice \": metric_val['Dice'],\n        \"Val Pixel Acc\": metric_val['Pixel_Acc'],\n        \"Val Precision\":metric_val[\"Precision\"],\n        \"Val Recall\": metric_val['Recall'],\n        \"Val Specificity\":metric_val['Specificity'],\n        \"Val Loss\" : loss_valid\n       })\n    if acc_valid>prev_acc:\n      prev_acc=acc_valid\n      paths = \"model\"+str(acc_valid)+\".pt\"\n      print('Saving Model')\n      torch.save({\n          'epoch': epoch,\n          'model_state_dict': model.state_dict(),\n          'optimizer_state_dict': optimizer.state_dict(),\n          'val_loss': loss_valid,\n          'val_acc':acc_valid,\n          'train_acc':acc_train,\n          'loss_acc':loss_train,\n          }, str(paths))\n\nprint(\"Time Elapsed : {:.4f}s\".format(time.time() - start_time))","metadata":{"execution":{"iopub.status.busy":"2021-05-23T09:38:35.860969Z","iopub.execute_input":"2021-05-23T09:38:35.861287Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:243jzkno) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 460<br/>Program ended successfully."},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Problem finishing run\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 1485, in _atexit_cleanup\n    self._on_finish()\n  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 1642, in _on_finish\n    self._backend.interface.publish_telemetry(self._telemetry_obj)\n  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py\", line 226, in publish_telemetry\n    self._publish(rec)\n  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py\", line 518, in _publish\n    raise Exception(\"The wandb backend process has shutdown\")\nException: The wandb backend process has shutdown\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"...Successfully finished last run (ID:243jzkno). Initializing new run:<br/><br/>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                Tracking run with wandb version 0.10.23<br/>\n                Syncing run <strong style=\"color:#cdcd00\">Clouds</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/creganstark/UNetResnet%2BWBCE%2BAugs\" target=\"_blank\">https://wandb.ai/creganstark/UNetResnet%2BWBCE%2BAugs</a><br/>\n                Run page: <a href=\"https://wandb.ai/creganstark/UNetResnet%2BWBCE%2BAugs/runs/pth8b8ln\" target=\"_blank\">https://wandb.ai/creganstark/UNetResnet%2BWBCE%2BAugs/runs/pth8b8ln</a><br/>\n                Run data is saved locally in <code>/kaggle/working/wandb/run-20210523_093835-pth8b8ln</code><br/><br/>\n            "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/490 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a20ef108f33a4016ad419821bd046278"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"370532db8dca42c8b216eb271f6a3eb0"}},"metadata":{}},{"name":"stdout","text":"Epoch: 1  Train Loss: 0.4553  Train IoU: 0.6012  Valid Loss: 0.6552  Valid IoU: 0.6537\nTrain Metrics {'IoU': tensor(0.8930, device='cuda:0'), 'Dice': tensor(0.9435, device='cuda:0'), 'Pixel_Acc': tensor(0.9444, device='cuda:0'), 'Precision': tensor(0.9625, device='cuda:0'), 'Recall': tensor(0.9252, device='cuda:0'), 'Specificity': tensor(0.9637, device='cuda:0')}\nVal. Metrics {'IoU': tensor(0.5229, device='cuda:0'), 'Dice': tensor(0.6867, device='cuda:0'), 'Pixel_Acc': tensor(0.7753, device='cuda:0'), 'Precision': tensor(0.6337, device='cuda:0'), 'Recall': tensor(0.7494, device='cuda:0'), 'Specificity': tensor(0.7880, device='cuda:0')}\nSaving Model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/490 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd4feacada5444908235ca796972dabc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc3421d463264ca4bf397e4623539d5d"}},"metadata":{}},{"name":"stdout","text":"Epoch: 2  Train Loss: 0.4160  Train IoU: 0.6378  Valid Loss: 0.5492  Valid IoU: 0.6828\nTrain Metrics {'IoU': tensor(0.6091, device='cuda:0'), 'Dice': tensor(0.7571, device='cuda:0'), 'Pixel_Acc': tensor(0.8013, device='cuda:0'), 'Precision': tensor(0.6112, device='cuda:0'), 'Recall': tensor(0.9943, device='cuda:0'), 'Specificity': tensor(0.7139, device='cuda:0')}\nVal. Metrics {'IoU': tensor(0.5959, device='cuda:0'), 'Dice': tensor(0.7468, device='cuda:0'), 'Pixel_Acc': tensor(0.7698, device='cuda:0'), 'Precision': tensor(0.5994, device='cuda:0'), 'Recall': tensor(0.9901, device='cuda:0'), 'Specificity': tensor(0.6549, device='cuda:0')}\nSaving Model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/490 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7efee2cd1d934d43b9fee7ea0db2ca0f"}},"metadata":{}}]},{"cell_type":"code","source":"paths='5epochsunet100.pt'\ntorch.save({\n          'epoch': epoch,\n          'model_state_dict': model.state_dict(),\n          'optimizer_state_dict': optimizer.state_dict(),\n          'val_loss': loss_valid,\n          'val_acc':acc_valid,\n          'train_acc':acc_train,\n          'loss_acc':loss_train,\n          }, str(paths))","metadata":{"execution":{"iopub.status.busy":"2021-05-23T09:25:12.563208Z","iopub.execute_input":"2021-05-23T09:25:12.563567Z","iopub.status.idle":"2021-05-23T09:25:14.348829Z","shell.execute_reply.started":"2021-05-23T09:25:12.563535Z","shell.execute_reply":"2021-05-23T09:25:14.348042Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"filename = 'modeltensor(0.8623, device='+'-cuda'+':'+'0-'+').pt'\nfilename=filename.replace('-',\"'\")","metadata":{"execution":{"iopub.status.busy":"2021-05-23T09:28:01.407420Z","iopub.execute_input":"2021-05-23T09:28:01.407860Z","iopub.status.idle":"2021-05-23T09:28:01.413003Z","shell.execute_reply.started":"2021-05-23T09:28:01.407823Z","shell.execute_reply":"2021-05-23T09:28:01.412198Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#filename = 'modeltensor(0.8413, device='cuda:0').pt\ndef load_checkpoint(model,filepath):\n    checkpoint = torch.load(filepath)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    #for parameter in model.parameters():\n        #parameter.requires_grad = True\n    return model\nmodel=load_checkpoint(model,filename)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T09:28:08.397554Z","iopub.execute_input":"2021-05-23T09:28:08.397867Z","iopub.status.idle":"2021-05-23T09:28:08.732902Z","shell.execute_reply.started":"2021-05-23T09:28:08.397839Z","shell.execute_reply":"2021-05-23T09:28:08.732028Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_length=int(0.7* len(dataset))\n\ntest_length=len(dataset)-train_length\nval_length=350\n\ntrain_dataset,test_dataset=torch.utils.data.random_split(dataset,(train_length,test_length))\ntest_length=test_length-val_length\nval_set,_=torch.utils.data.random_split(test_dataset,(val_length,test_length))\nbatch_size= 12\n\ntrainloader = DataLoader(train_dataset,\n        batch_size=batch_size, shuffle=True,num_workers= 2)\ntestloader = DataLoader(val_set,\n        batch_size=batch_size, shuffle=False,num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T09:29:28.614361Z","iopub.execute_input":"2021-05-23T09:29:28.614713Z","iopub.status.idle":"2021-05-23T09:29:28.622429Z","shell.execute_reply.started":"2021-05-23T09:29:28.614684Z","shell.execute_reply":"2021-05-23T09:29:28.621315Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}